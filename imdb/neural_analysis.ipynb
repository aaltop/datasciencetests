{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from src.data_handling import process_training_data\n",
    "from src.mlflow_setup import mlflow_setup\n",
    "\n",
    "mlflow_setup()\n",
    "mlflow.set_experiment(\"Neural analysis\")\n",
    "tb_writer = SummaryWriter()\n",
    "\n",
    "data_path = Path() / \"data\"\n",
    "source_data_path = data_path / \"imdb.csv\"\n",
    "imdb_data = pd.read_csv(source_data_path)\n",
    "\n",
    "\n",
    "full_context_counts_path = data_path / \"full_context_counts.csv\"\n",
    "if not (os.path.exists(full_context_counts_path)):\n",
    "    process_training_data(\n",
    "        imdb_data.review,\n",
    "        imdb_data.sentiment,\n",
    "        full_context_counts_path\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_more_than = 99\n",
    "context_counts = pd.read_csv(full_context_counts_path).query(f\"total > {words_more_than}\")\n",
    "print(context_counts.word.is_unique)\n",
    "mlflow.log_input(\n",
    "    mlflow.data.from_pandas(\n",
    "        context_counts,\n",
    "        source=str(full_context_counts_path),\n",
    "        name=\"context counts\"\n",
    "    )\n",
    ")\n",
    "context_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_handling import process_test_data\n",
    "\n",
    "test_data_path = data_path / \"stemmed_data.csv\"\n",
    "\n",
    "if not (os.path.exists(test_data_path)):\n",
    "    process_test_data(\n",
    "        imdb_data.review,\n",
    "        imdb_data.sentiment,\n",
    "        test_data_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_handling import test_data_to_numeric\n",
    "\n",
    "import torch\n",
    "\n",
    "# write new numeric test data based on context_counts\n",
    "# ---------------------------------------------------\n",
    "\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "mlflow.log_input(\n",
    "    mlflow.data.from_pandas(\n",
    "        test_data,\n",
    "        source=str(test_data_path),\n",
    "        name=\"test data\"\n",
    "    )\n",
    ")\n",
    "\n",
    "used_words = context_counts.word\n",
    "numeric_test_data_path = data_path / \"numeric_stemmed_data.parquet\"\n",
    "compute = False\n",
    "if compute:\n",
    "    test_data_to_numeric(\n",
    "        test_data.context,\n",
    "        test_data.words,\n",
    "        used_words,\n",
    "        numeric_test_data_path\n",
    "    )\n",
    "# =========================================================\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "dtype = torch.float32\n",
    "class ImdbDataSet(torch.utils.data.TensorDataset):\n",
    "\n",
    "    def __init__(self, data_path, start_row=0, end_row = None, device = None):\n",
    "        '''\n",
    "        Arguments:\n",
    "            dtype:\n",
    "                should be of integer dtype suitable for torch tensors\n",
    "        '''\n",
    "\n",
    "\n",
    "        data = pd.read_parquet(data_path)[start_row:]\n",
    "        if not (end_row is None):\n",
    "            data = data[:end_row]\n",
    "\n",
    "        # create context mappings\n",
    "        context_categorical = pd.Categorical(data[\"__context__\"])\n",
    "        self.context = context_categorical.codes\n",
    "        self.context_mapping = dict(zip(context_categorical.categories, self.context))\n",
    "\n",
    "        self.device = device or \"cpu\"\n",
    "        # needs to be int64 for nll loss, seemingly\n",
    "        # could also just directly calculate though, which would\n",
    "        # allow using at least int32\n",
    "        self.context = torch.tensor(self.context, dtype=torch.int64, device=device)\n",
    "        \n",
    "        self.words = torch.tensor(data.iloc[:,1:].to_numpy(), dtype=torch.float32, device=self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.context)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.words[idx], self.context[idx]\n",
    "\n",
    "    def numeric_context_to_word(self):\n",
    "\n",
    "        return list(map(lambda val: self.context_mapping[str(int(val))], self.context))\n",
    "\n",
    "\n",
    "# It's not really test data, because it's now used as\n",
    "# the training for the model, but the previous data is\n",
    "# training data also, as it's used as the basis for\n",
    "# processing this here \"test\" data.\n",
    "train_size = 40000\n",
    "mlflow.log_param(\"train set size\", train_size)\n",
    "train_dataset = ImdbDataSet(\n",
    "    numeric_test_data_path,\n",
    "    end_row=train_size,\n",
    "    device=device\n",
    ")\n",
    "eval_size = 5000\n",
    "mlflow.log_param(\"eval set size\", eval_size)\n",
    "eval_dataset = ImdbDataSet(\n",
    "    numeric_test_data_path,\n",
    "    start_row=train_size,\n",
    "    end_row=train_size+eval_size,\n",
    "    device=device\n",
    ")\n",
    "test_dataset = ImdbDataSet(\n",
    "    numeric_test_data_path,\n",
    "    start_row=train_size+eval_size,\n",
    "    device=device\n",
    ")\n",
    "mlflow.log_param(\"test set size\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset), len(test_dataset))\n",
    "words, context = train_dataset[:]\n",
    "print(\"Data sparsity:\", words.to(dtype = torch.float32).mean())\n",
    "del words\n",
    "del context\n",
    "train_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many words to use from context_counts\n",
    "num_used_words = len(used_words)\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    word_vecs = torch.nn.Linear(\n",
    "        in_features=num_used_words,\n",
    "        out_features=8,\n",
    "        bias=False,\n",
    "        device=device,\n",
    "        dtype=dtype\n",
    "    )\n",
    "\n",
    "    # standard initialisation\n",
    "    torch.nn.init.constant_(word_vecs.weight, 1/torch.numel(word_vecs.weight))\n",
    "\n",
    "    return torch.nn.Sequential(\n",
    "        word_vecs,\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(\n",
    "            in_features=8,\n",
    "            out_features=4,\n",
    "            bias=True,\n",
    "            device=device,\n",
    "            dtype=dtype\n",
    "        ),\n",
    "        torch.nn.Linear(\n",
    "            in_features=4,\n",
    "            out_features=2,\n",
    "            bias=False,\n",
    "            device=device,\n",
    "            dtype=dtype\n",
    "        ),\n",
    "        torch.nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "\n",
    "model = get_model()\n",
    "artifacts_path = Path() / \"artifacts\"\n",
    "artifacts_path.mkdir(exist_ok=True)\n",
    "model_desc_path = artifacts_path / \"model_description.txt\"\n",
    "with open(model_desc_path, \"w\") as f:\n",
    "    print(model, file=f)\n",
    "\n",
    "mlflow.log_artifact(model_desc_path)\n",
    "\n",
    "print(next(model[0].parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 20\n",
    "shuffle = True\n",
    "mlflow.log_param(\"batch size\", batch_size)\n",
    "mlflow.log_param(\"shuffle during training\", shuffle)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "_ = next(iter(train_dataloader))\n",
    "print(_)\n",
    "print(_[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, context = train_dataset[:5]\n",
    "pred = model(words.to(dtype = torch.float32))\n",
    "\n",
    "tb_writer.add_graph(model, words.to(dtype = torch.float32))\n",
    "\n",
    "print(pred)\n",
    "print(context)\n",
    "predicted_class = pred.argmax(dim=1)\n",
    "print(f\"{predicted_class=}\")\n",
    "nlll = torch.nn.NLLLoss()\n",
    "print(nlll(pred, context))\n",
    "-pred[range(len(context)), context].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is to train the vectors for the words as the weight matrix\n",
    "of the first layer. The matrix would get updated according to the loss,\n",
    "so that a vector that matches a negative word should result in a more\n",
    "negative guess, and similarly for positive words. Further, words that\n",
    "appear together get updated similarly.\n",
    "\n",
    "Not sure whether these should be updated in batches or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = get_model()\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "loss_path = artifacts_path / \"loss.txt\"\n",
    "with open(loss_path, \"w\") as f:\n",
    "    print(loss_fn, file=f)\n",
    "mlflow.log_artifact(loss_path)\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "optim_path = artifacts_path / \"optim.txt\"\n",
    "with open(optim_path, \"w\") as f:\n",
    "    print(optim, file=f)\n",
    "\n",
    "\n",
    "losses = []\n",
    "train_accs = []\n",
    "eval_accs = []\n",
    "\n",
    "def test(model, test_data):\n",
    "\n",
    "    words, context = test_data[:]\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pred = model(words).argmax(dim=1)\n",
    "        \n",
    "        acc = 1-torch.abs(context-pred).mean(dtype=float)\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    return acc.item()\n",
    "\n",
    "total_epochs = 5\n",
    "mlflow.log_param(\"epochs\", total_epochs)\n",
    "for epoch in range(total_epochs):\n",
    "\n",
    "    epoch_loss = []\n",
    "    for i, (words, context) in enumerate(train_dataloader):\n",
    "\n",
    "        pred = model(words)\n",
    "        loss = loss_fn(pred, context)\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "\n",
    "    mean_epoch_loss = torch.tensor(epoch_loss).mean().item()\n",
    "\n",
    "    tb_writer.add_scalar(\"mean_epoch_loss/train\", mean_epoch_loss, global_step=epoch)\n",
    "    mlflow.log_metric(\"mean epoch loss\", mean_epoch_loss, step=epoch)\n",
    "    losses.extend(epoch_loss)\n",
    "\n",
    "    train_acc = test(model, train_dataset)\n",
    "    mlflow.log_metric(\"train accuracy\", train_acc, step=epoch)\n",
    "    print(f\"{train_acc=}\")\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    eval_acc = test(model, eval_dataset)\n",
    "    mlflow.log_metric(\"eval accuracy\", eval_acc, step=epoch)\n",
    "\n",
    "    tb_writer.add_scalars(\"accuracy\", dict(\n",
    "        evaluation=eval_acc,\n",
    "        train=train_acc\n",
    "    ), global_step=epoch)\n",
    "\n",
    "    print(f\"{eval_acc=}\")\n",
    "    eval_accs.append(eval_acc)\n",
    "\n",
    "losses = torch.tensor(losses)\n",
    "\n",
    "\n",
    "sig = mlflow.models.infer_signature(\n",
    "    words.cpu().numpy(),\n",
    "    model(words).detach().cpu().numpy()\n",
    ")\n",
    "mlflow.pytorch.log_model(model, \"model\", signature=sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "\n",
    "print(losses.size())\n",
    "\n",
    "window = 50\n",
    "rolling_average_loss = list(\n",
    "    map(lambda val: sum(val)/window, itertools.batched(losses, window))\n",
    ")\n",
    "print(f\"Mean: {losses.mean().item()}\")\n",
    "print(f\"Var: {losses.var().item()}\")\n",
    "print(f\"{eval_acc=}\")\n",
    "plt.plot(\n",
    "    rolling_average_loss,\n",
    ")\n",
    "_ = plt.title(f\"Rolling average loss, window: {window}\\n epochs: {total_epochs} data per epoch: {len(train_dataset)} batch size: {batch_size}\")\n",
    "# plt.plot(sorted(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(used_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vector representations of the words from the model\n",
    "word_vecs = next(iter(model.parameters())).T.clone().detach()\n",
    "chosen_idx = 19\n",
    "# vector representation of the word\n",
    "chosen_word = word_vecs[chosen_idx]\n",
    "# actual word itself\n",
    "print(\"Chosen word:\", used_words[chosen_idx])\n",
    "\n",
    "# determine how similar each of the other words is to this one\n",
    "cos = torch.nn.CosineSimilarity(dim=-1)\n",
    "similarities = torch.tensor([cos(chosen_word, word_vecs[i]) for i in range(len(word_vecs))])\n",
    "most_similar = torch.argsort(similarities, descending=True)\n",
    "plt.plot(similarities.flatten().sort()[0])\n",
    "print(*used_words[most_similar.numpy()].to_list(), sep=\"\\n\", file=open(\"temp.dat\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words, context = test_dataset[:]\n",
    "model.eval()\n",
    "pred = model(words).detach()\n",
    "print(pred)\n",
    "print(torch.exp(pred))\n",
    "print(context)\n",
    "acc = 1-torch.abs(context - pred.argmax(dim=1)).mean(dtype=float)\n",
    "mlflow.log_metric(\"test accuracy\", acc)\n",
    "print(f\"{acc=}\")\n",
    "pred = torch.exp(pred)\n",
    "# how far the predictions were from the true value\n",
    "surprise = 1-torch.gather(pred, 1, context.reshape((-1,1)))\n",
    "surprise = surprise.flatten().to(device=\"cpu\")\n",
    "print(surprise)\n",
    "\n",
    "surprise_mean = surprise.mean(dtype=float)\n",
    "print(f\"Mean of surprises: {surprise_mean}\")\n",
    "plt.hist(surprise)\n",
    "plt.title(\"Distribution of surprises\")\n",
    "mlflow.log_figure(plt.gcf(), \"surprise.png\")\n",
    "plt.figure()\n",
    "plt.plot(surprise.sort().values)\n",
    "plt.title(\"Sorted surprises\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "tb_writer.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
