{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from src.data_handling import process_training_data\n",
    "from src.mlflow_setup import mlflow_setup\n",
    "\n",
    "mlflow_setup()\n",
    "mlflow.set_experiment(\"Neural analysis\")\n",
    "tb_writer = SummaryWriter()\n",
    "\n",
    "data_path = Path() / \"data\"\n",
    "source_data_path = data_path / \"imdb.csv\"\n",
    "imdb_data = pd.read_csv(source_data_path)\n",
    "\n",
    "\n",
    "full_context_counts_path = data_path / \"full_context_counts.csv\"\n",
    "if not (os.path.exists(full_context_counts_path)):\n",
    "    process_training_data(\n",
    "        imdb_data.review,\n",
    "        imdb_data.sentiment,\n",
    "        full_context_counts_path\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_more_than = 19\n",
    "mlflow.log_param(\"words_more_than\", words_more_than)\n",
    "context_counts = pd.read_csv(full_context_counts_path).query(f\"total > {words_more_than}\")\n",
    "# neg_pos_diff = (context_counts[\"negative\"]-context_counts[\"positive\"])/context_counts[\"total\"]\n",
    "# neg_pos_diff_more_than = 0.2\n",
    "# mlflow.log_param(\"neg_pos_diff_more_than\", neg_pos_diff_more_than)\n",
    "# context_counts = context_counts[neg_pos_diff.abs() > neg_pos_diff_more_than]\n",
    "print(context_counts.word.is_unique)\n",
    "mlflow.log_input(\n",
    "    mlflow.data.from_pandas(\n",
    "        context_counts,\n",
    "        source=str(full_context_counts_path),\n",
    "        name=\"context counts\"\n",
    "    )\n",
    ")\n",
    "context_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_handling import process_test_data\n",
    "\n",
    "test_data_path = data_path / \"stemmed_data.csv\"\n",
    "\n",
    "if not (os.path.exists(test_data_path)):\n",
    "    process_test_data(\n",
    "        imdb_data.review,\n",
    "        imdb_data.sentiment,\n",
    "        test_data_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_handling import SparseNumericTestDataIO, SparseNumericTestData\n",
    "\n",
    "import torch\n",
    "\n",
    "# write new numeric test data based on context_counts\n",
    "# ---------------------------------------------------\n",
    "\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "mlflow.log_input(\n",
    "    mlflow.data.from_pandas(\n",
    "        test_data,\n",
    "        source=str(test_data_path),\n",
    "        name=\"test data\"\n",
    "    )\n",
    ")\n",
    "\n",
    "used_words = context_counts.word\n",
    "numeric_test_data_path = data_path / \"sparse_numeric_stemmed_data.dat\"\n",
    "compute = True\n",
    "if compute:\n",
    "    SparseNumericTestDataIO(\n",
    "        test_data.context,\n",
    "        test_data.words,\n",
    "        used_words\n",
    "    ).write(numeric_test_data_path)\n",
    "\n",
    "sparse_numeric_test_data = SparseNumericTestDataIO.read(numeric_test_data_path)\n",
    "# =========================================================\n",
    "\n",
    "# the sparse numeric adds <unk> token (and possibly others), so redo used_words\n",
    "used_words = pd.Series(sparse_numeric_test_data.train_words_dict.values())\n",
    "used_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "dtype = torch.float32\n",
    "class ImdbDataSet(torch.utils.data.TensorDataset):\n",
    "\n",
    "    def __init__(self, data: SparseNumericTestData, start_row=0, end_row: int|None = None, device = None):\n",
    "        '''\n",
    "        Arguments:\n",
    "            dtype:\n",
    "                should be of integer dtype suitable for torch tensors\n",
    "        '''\n",
    "\n",
    "        end_row = len(data) if end_row is None else end_row\n",
    "        data = data[start_row:end_row]\n",
    "\n",
    "        # create context mappings\n",
    "        contexts, indices = zip(*data.context_and_indices)\n",
    "        context_categorical = pd.Categorical(contexts)\n",
    "        self.context = context_categorical.codes\n",
    "        self.context_mapping = dict(zip(context_categorical.categories, self.context))\n",
    "\n",
    "        self.device = device or \"cpu\"\n",
    "        # needs to be int64 for nll loss, seemingly\n",
    "        # could also just directly calculate though, which would\n",
    "        # allow using at least int32\n",
    "        self.context = torch.tensor(self.context, dtype=torch.int64, device=device)\n",
    "        \n",
    "        words = torch.tensor(list(map(data.indices_to_weight, indices)), dtype=torch.float32, device=self.device)\n",
    "        self.words = words\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.context)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.words[idx], self.context[idx]\n",
    "\n",
    "    def numeric_context_to_word(self):\n",
    "\n",
    "        return list(map(lambda val: self.context_mapping[str(int(val))], self.context))\n",
    "\n",
    "\n",
    "train_size, eval_size, test_size = 45000, 2500, 2500\n",
    "# It's not really test data, because it's now used as\n",
    "# the training for the model, but the previous data is\n",
    "# training data also, as it's used as the basis for\n",
    "# processing this here \"test\" data.\n",
    "mlflow.log_param(\"train set size\", train_size)\n",
    "train_dataset = ImdbDataSet(\n",
    "    sparse_numeric_test_data,\n",
    "    end_row=train_size,\n",
    "    device=device\n",
    ")\n",
    "mlflow.log_param(\"eval set size\", eval_size)\n",
    "eval_dataset = ImdbDataSet(\n",
    "    sparse_numeric_test_data,\n",
    "    start_row=train_size,\n",
    "    end_row=train_size+eval_size,\n",
    "    device=device\n",
    ")\n",
    "test_dataset = ImdbDataSet(\n",
    "    sparse_numeric_test_data,\n",
    "    start_row=train_size+eval_size,\n",
    "    end_row=train_size+eval_size+test_size,\n",
    "    device=device\n",
    ")\n",
    "mlflow.log_param(\"test set size\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset), len(test_dataset))\n",
    "words, context = train_dataset[:]\n",
    "words = words.cpu()\n",
    "print(\"Data sparsity:\", words.to(dtype=bool).to(dtype=float).mean())\n",
    "del words\n",
    "del context\n",
    "train_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many training words are being used\n",
    "num_used_words = len(used_words)\n",
    "\n",
    "embedding_dim = 8\n",
    "mlflow.log_param(\"embedding dimension\", embedding_dim)\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "        self.word_vecs = torch.nn.Linear(\n",
    "            in_features=num_used_words,\n",
    "            out_features=embedding_dim,\n",
    "            bias=False,\n",
    "            device=device,\n",
    "            dtype=dtype\n",
    "        )\n",
    "        # standard initialisation\n",
    "        torch.nn.init.constant_(self.word_vecs.weight, 1/torch.numel(self.word_vecs.weight))\n",
    "\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.LazyLinear(\n",
    "                out_features=4,\n",
    "                bias=True,\n",
    "                device=device,\n",
    "                dtype=dtype\n",
    "            ),\n",
    "            torch.nn.LazyLinear(\n",
    "                out_features=2,\n",
    "                bias=False,\n",
    "                device=device,\n",
    "                dtype=dtype\n",
    "            ),\n",
    "            torch.nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def embeddings(self):\n",
    "        return self.word_vecs.weight.detach().clone()\n",
    "    \n",
    "    @embeddings.setter\n",
    "    def embeddings(self, x):\n",
    "        self.word_vecs.weight.data = torch.nn.parameter.Parameter(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net.forward(self.word_vecs(x))\n",
    "\n",
    "\n",
    "model = Model()\n",
    "artifacts_path = Path() / \"artifacts\"\n",
    "artifacts_path.mkdir(exist_ok=True)\n",
    "model_desc_path = artifacts_path / \"model_description.txt\"\n",
    "with open(model_desc_path, \"w\") as f:\n",
    "    print(model, file=f)\n",
    "\n",
    "mlflow.log_artifact(model_desc_path)\n",
    "\n",
    "print(model.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 300\n",
    "shuffle = True\n",
    "mlflow.log_param(\"batch size\", batch_size)\n",
    "mlflow.log_param(\"shuffle during training\", shuffle)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "_ = next(iter(train_dataloader))\n",
    "print(_)\n",
    "print(_[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, context = train_dataset[:5]\n",
    "pred = model(words.to(dtype = torch.float32))\n",
    "\n",
    "tb_writer.add_graph(model, words.to(dtype = torch.float32))\n",
    "\n",
    "print(pred)\n",
    "print(context)\n",
    "predicted_class = pred.argmax(dim=1)\n",
    "print(f\"{predicted_class=}\")\n",
    "nlll = torch.nn.NLLLoss()\n",
    "print(nlll(pred, context))\n",
    "-pred[range(len(context)), context].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is to train the vectors for the words as the weight matrix\n",
    "of the first layer. The matrix would get updated according to the loss,\n",
    "so that a vector that matches a negative word should result in a more\n",
    "negative guess, and similarly for positive words. Further, words that\n",
    "appear together get updated similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "model = Model()\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "loss_path = artifacts_path / \"loss.txt\"\n",
    "with open(loss_path, \"w\") as f:\n",
    "    print(loss_fn, file=f)\n",
    "mlflow.log_artifact(loss_path)\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "optim_path = artifacts_path / \"optim.txt\"\n",
    "with open(optim_path, \"w\") as f:\n",
    "    print(optim, file=f)\n",
    "\n",
    "\n",
    "losses = []\n",
    "train_accs = []\n",
    "eval_accs = []\n",
    "\n",
    "def test(model, test_data):\n",
    "\n",
    "    words, context = test_data[:]\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pred = model(words).argmax(dim=1)\n",
    "        \n",
    "        acc = 1-torch.abs(context-pred).mean(dtype=float)\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    return acc.item()\n",
    "\n",
    "def unit_normalisation(embedding:torch.Tensor):\n",
    "    new_embed = embedding\n",
    "    new_embed -= new_embed.min(dim=1).values.reshape(-1,1) - 1e-3\n",
    "    new_embed /= torch.max(new_embed, torch.ones_like(new_embed)*1e-6).max(dim=1).values.reshape(-1,1)\n",
    "    return new_embed\n",
    "\n",
    "def unit_normalisation_with_constant(embedding:torch.Tensor):\n",
    "    new_embed = unit_normalisation(embedding)\n",
    "    new_embed[0,:] = 1.0\n",
    "    return new_embed\n",
    "\n",
    "total_epochs = 20\n",
    "mlflow.log_param(\"epochs\", total_epochs)\n",
    "max_eval = 0.0\n",
    "for epoch in range(total_epochs):\n",
    "\n",
    "    epoch_loss = []\n",
    "    for i, (words, context) in enumerate(train_dataloader):\n",
    "\n",
    "        pred = model(words)\n",
    "        loss = loss_fn(pred, context)/batch_size\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # normalise\n",
    "        # ------------\n",
    "        model.embeddings = unit_normalisation(model.embeddings)\n",
    "        # ==================\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "\n",
    "    mean_epoch_loss = torch.tensor(epoch_loss).mean().item()\n",
    "\n",
    "    tb_writer.add_scalar(\"mean_epoch_loss/train\", mean_epoch_loss, global_step=epoch)\n",
    "    mlflow.log_metric(\"mean epoch loss\", mean_epoch_loss, step=epoch)\n",
    "    losses.extend(epoch_loss)\n",
    "\n",
    "    train_acc = test(model, train_dataset)\n",
    "    mlflow.log_metric(\"train accuracy\", train_acc, step=epoch)\n",
    "    print(f\"{train_acc=}\")\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    eval_acc = test(model, eval_dataset)\n",
    "    mlflow.log_metric(\"eval accuracy\", eval_acc, step=epoch)\n",
    "    if eval_acc > max_eval:\n",
    "        best_state_dict = deepcopy(model.state_dict())\n",
    "        max_eval = eval_acc\n",
    "        best_epoch = epoch\n",
    "\n",
    "    tb_writer.add_scalars(\"accuracy\", dict(\n",
    "        evaluation=eval_acc,\n",
    "        train=train_acc\n",
    "    ), global_step=epoch)\n",
    "\n",
    "    print(f\"{eval_acc=}\")\n",
    "    eval_accs.append(eval_acc)\n",
    "\n",
    "losses = torch.tensor(losses)\n",
    "\n",
    "model.load_state_dict(best_state_dict)\n",
    "tb_writer.add_embedding(model.embeddings.cpu().T, used_words, global_step=best_epoch)\n",
    "sig = mlflow.models.infer_signature(\n",
    "    words.cpu().numpy(),\n",
    "    model(words).detach().cpu().numpy()\n",
    ")\n",
    "mlflow.pytorch.log_model(model, \"model\", signature=sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as mplstyle\n",
    "\n",
    "import itertools\n",
    "\n",
    "mplstyle.use([\"fast\"])\n",
    "\n",
    "print(losses.size())\n",
    "\n",
    "window = 50\n",
    "rolling_average_loss = list(\n",
    "    map(lambda val: sum(val)/window, itertools.batched(losses, window))\n",
    ")\n",
    "print(f\"Mean: {losses.mean().item()}\")\n",
    "print(f\"Var: {losses.var().item()}\")\n",
    "print(f\"{eval_acc=}\")\n",
    "plt.close(\"all\")\n",
    "plt.plot(\n",
    "    rolling_average_loss,\n",
    ")\n",
    "_ = plt.title(f\"Rolling average loss, window: {window}\\n epochs: {total_epochs} data per epoch: {len(train_dataset)} batch size: {batch_size}\")\n",
    "# plt.plot(sorted(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(used_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vector representations of the words from the model\n",
    "word_vecs = model.embeddings.cpu().T.clone().detach()\n",
    "chosen_idx = int(used_words[used_words == \"bad\"].index[0])\n",
    "chosen_idx = int(used_words[used_words == \"excel\"].index[0])\n",
    "print(\"Chosen idx: \", chosen_idx)\n",
    "# vector representation of the word\n",
    "chosen_word = word_vecs[chosen_idx]\n",
    "# actual word itself\n",
    "print(\"Chosen word:\", used_words[chosen_idx])\n",
    "\n",
    "# determine how similar each of the other words is to this one\n",
    "cos = torch.nn.PairwiseDistance()\n",
    "similarities = torch.tensor([cos(chosen_word, word_vecs[i]) for i in range(len(word_vecs))])\n",
    "most_similar = torch.argsort(similarities, descending=False)\n",
    "plt.plot(similarities.flatten().sort()[0])\n",
    "similars_list = used_words[most_similar.numpy()].to_list()\n",
    "print(*similars_list, sep=\"\\n\", file=open(\"temp.dat\", \"w\"))\n",
    "pd.DataFrame(dict(most_similar=similars_list[:20], least_similar=reversed(similars_list[-20:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs[int(used_words[used_words == \"<unk>\"].index[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "ax.scatter(*word_vecs.T[[0,1],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "words, context = test_dataset[:]\n",
    "model.eval()\n",
    "pred = model(words).detach()\n",
    "print(pred)\n",
    "print(torch.exp(pred))\n",
    "print(context)\n",
    "acc = 1-torch.abs(context - pred.argmax(dim=1)).mean(dtype=float)\n",
    "mlflow.log_metric(\"test accuracy\", acc)\n",
    "print(f\"{acc=}\")\n",
    "pred = torch.exp(pred)\n",
    "# how far the predictions were from the true value\n",
    "surprise = 1-torch.gather(pred, 1, context.reshape((-1,1)))\n",
    "surprise = surprise.flatten().to(device=\"cpu\")\n",
    "print(surprise)\n",
    "\n",
    "surprise_mean = surprise.mean(dtype=float)\n",
    "print(f\"Mean of surprises: {surprise_mean}\")\n",
    "plt.close(\"all\")\n",
    "plt.hist(surprise)\n",
    "plt.title(\"Distribution of surprises\")\n",
    "mlflow.log_figure(plt.gcf(), \"surprise.png\")\n",
    "plt.figure()\n",
    "plt.plot(surprise.sort().values)\n",
    "plt.title(\"Sorted surprises\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "tb_writer.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
