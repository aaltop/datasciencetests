{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read from Kaggle, unzip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as urlrequest\n",
    "from pathlib import Path\n",
    "\n",
    "base_data_path = Path() / \"data\" \n",
    "\n",
    "base_data_path.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "dataset_location = base_data_path / \"dataset\"\n",
    "\n",
    "zip_path = base_data_path / \"dataset.zip\"\n",
    "\n",
    "if not zip_path.exists():\n",
    "\n",
    "    dataset_url = \"https://www.kaggle.com/api/v1/datasets/download/alvarole/asirra-cats-vs-dogs-object-detection-dataset\"\n",
    "\n",
    "    response = urlrequest.urlopen(\n",
    "        dataset_url,\n",
    "    )\n",
    "\n",
    "    download_size = response.getheader(\"Content-Length\")\n",
    "    with open(zip_path, \"wb\") as f:\n",
    "\n",
    "        f.write(response.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def unzip():\n",
    "\n",
    "    inner_file = \"Asirra_ cat vs dogs\"\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip:\n",
    "        \n",
    "        for item in zip.infolist():\n",
    "\n",
    "            zip.extract(item, base_data_path)\n",
    "\n",
    "    os.rename(base_data_path / inner_file, dataset_location)\n",
    "\n",
    "# unzip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "\n",
    "\n",
    "def patched_dataset_paths(dataset_location):\n",
    "\n",
    "    return itertools.batched(dataset_location.iterdir(), 2)\n",
    "\n",
    "\n",
    "# specific xml reader implementation for the lolz\n",
    "def read_metadata(xml_file: Path):\n",
    "    '''\n",
    "    Read labeling from xml file into dict.\n",
    "    '''\n",
    "\n",
    "    with open(xml_file, \"r\", encoding = \"utf-8\") as f:\n",
    "        text = ET.canonicalize(from_file=f, strip_text = True)\n",
    "        \n",
    "    tree = ET.fromstring(text)\n",
    "\n",
    "    size = tree.find(\"size\")\n",
    "    size = {elem.tag: int(elem.text) for elem in size.iter() if not elem.tag == \"size\"}\n",
    "\n",
    "\n",
    "    objects = tree.findall(\"object\")\n",
    "    objects = [dict(\n",
    "        name = obj.find(\"name\").text,\n",
    "        pose = obj.find(\"pose\").text,\n",
    "        truncated = int(obj.find(\"truncated\").text),\n",
    "        difficult = int(obj.find(\"difficult\").text),\n",
    "        bndbox = {\n",
    "            elem.tag: float(elem.text) \n",
    "            for elem in obj.find(\"bndbox\").iter()\n",
    "            if not elem.tag == \"bndbox\"\n",
    "        }\n",
    "    ) for obj in objects]\n",
    "\n",
    "    metadata = dict(\n",
    "        size = size,\n",
    "        objects = objects\n",
    "    )\n",
    "\n",
    "    return metadata\n",
    "\n",
    "def get_dataset(dataset_location) -> list[dict]:\n",
    "\n",
    "    meta = []\n",
    "    for img, xml_path in patched_dataset_paths(dataset_location):\n",
    "\n",
    "        metadata = read_metadata(xml_path) | dict(img_path = img)\n",
    "        meta.append(metadata)\n",
    "\n",
    "    return meta\n",
    "\n",
    "def dataset_splits(dataset: list | None = None, fractions: tuple[float] = (0.8, 0.1, 0.1)):\n",
    "\n",
    "    dataset = get_dataset(dataset_location) if dataset is None else dataset\n",
    "    return  torch.utils.data.random_split(dataset, fractions)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CatsAndDogsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform=None, target_transform=None):\n",
    "\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        metadata = self.data[idx]\n",
    "        img_path = metadata[\"img_path\"]\n",
    "        image = read_image(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            metadata = self.target_transform(metadata)\n",
    "        return image, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_split, validation_split, test_split = dataset_splits()\n",
    "\n",
    "train_split = CatsAndDogsDataset(train_split)\n",
    "validation_split = CatsAndDogsDataset(validation_split)\n",
    "test_split = CatsAndDogsDataset(test_split)\n",
    "\n",
    "print(len(train_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test datasets with plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as vision_transforms\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "\n",
    "def to_plottable(img):\n",
    "\n",
    "    return vision_transforms.to_pil_image(img)\n",
    "\n",
    "def add_bb(img, meta):\n",
    "\n",
    "    for object in meta[\"objects\"]:\n",
    "\n",
    "        bb = torch.tensor(list(object[\"bndbox\"].values())).reshape((-1, 4))\n",
    "        print(bb)\n",
    "        img = draw_bounding_boxes(img, bb, colors = \"cyan\")\n",
    "\n",
    "    return img\n",
    "\n",
    "plt.figure()\n",
    "im, meta = train_split[0]\n",
    "im = add_bb(im, meta)\n",
    "plt.imshow(to_plottable(im))\n",
    "print(meta[\"objects\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
